{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy - attack model - part1 : Wasserstein GAN\n",
    "\n",
    "__Main goal__ : the main goal of this part is to use public data to build a generator able to produce the kind of output we want to reveal. Here we want to reveal images of hand written digits from 0 to 4. We use images of hand written digits from 5 to 9 to train the generator, so that the public and private dataset do not overlap.\n",
    "\n",
    "__Reference for the WGAN__ : https://machinelearningmastery.com/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.sys.path.append(\"./src\")\n",
    "from utils import plot_img\n",
    "from utils import load_mnist_data\n",
    "\n",
    "from models import wasserstein_loss\n",
    "from models import define_critic\n",
    "from models import define_generator\n",
    "from models import generate_latent_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image dataset and check if we have only images from 5 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, y_train, x_test, y_test = load_mnist_data(\"public\")\n",
    "plot_img(dataset, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select real samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # select images\n",
    "    X = dataset[ix]\n",
    "    # generate class labels, -1 for 'real'\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the generator to generate n fake examples, with class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    X = generator.predict(x_input)\n",
    "    # create class labels with 1.0 for 'fake'\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate samples and save as a plot and save the model\n",
    "The critic and standalone generator functions are defined in scr/models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, critic):\n",
    "    # make weights in the critic not trainable\n",
    "    critic.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the critic\n",
    "    model.add(critic)\n",
    "    # compile model\n",
    "    opt = RMSprop(lr=0.00005)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances and models are saved regularly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, c_model, latent_dim, n_samples=100):\n",
    "    # prepare fake examples\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    X = (X + 1) / 2.0\n",
    "    # plot images\n",
    "    for i in range(10 * 10):\n",
    "        # define subplot\n",
    "        pyplot.subplot(10, 10, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "    # save plot to file\n",
    "    filename1 = 'attack_gan_plot_%04d.png' % (step+1)\n",
    "    pyplot.savefig(os.path.join(\"model\",filename1))\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    filename2 = os.path.join(\"model\",'attack_gan_model_%04d.h5' % (step+1))\n",
    "    g_model.save(filename2)\n",
    "    # save the critic model\n",
    "    filename3 = os.path.join(\"model\",'attack_critic_model_weights_%04d.h5' % (step+1))\n",
    "    c_model.save_weights(filename3)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a line plot of loss for the gan and save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(d1_hist, d2_hist, g_hist):\n",
    "    # plot history\n",
    "    pyplot.plot(d1_hist, label='crit_real')\n",
    "    pyplot.plot(d2_hist, label='crit_fake')\n",
    "    pyplot.plot(g_hist, label='gen')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig(os.path.join(\"model\",'attack_gan_loss.png'))\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the generator and critic\n",
    "The critic is trained x times more than the generator (here we choose x=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs, n_batch=64, n_critic=5):\n",
    "    # calculate the number of batches per training epoch\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    # calculate the size of half a batch of samples\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # lists for keeping track of loss\n",
    "    c1_hist, c2_hist, g_hist = list(), list(), list()\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # update the critic more than the generator\n",
    "        c1_tmp, c2_tmp = list(), list()\n",
    "        for _ in range(n_critic):\n",
    "            # get randomly selected 'real' samples\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            # update critic model weights\n",
    "            c_loss1 = c_model.train_on_batch(X_real, y_real)\n",
    "            c1_tmp.append(c_loss1)\n",
    "            # generate 'fake' examples\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # update critic model weights\n",
    "            c_model.trainable = True\n",
    "            c_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
    "            c2_tmp.append(c_loss2)\n",
    "        # store critic loss\n",
    "        c1_hist.append(mean(c1_tmp))\n",
    "        c2_hist.append(mean(c2_tmp))\n",
    "        # prepare points in latent space as input for the generator\n",
    "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = -ones((n_batch, 1))\n",
    "        # update the generator via the critic's error\n",
    "        c_model.trainable = False\n",
    "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "        g_hist.append(g_loss)        \n",
    "        # evaluate the model performance every 'epoch'\n",
    "        if (i+1) % bat_per_epo == 0:\n",
    "            print('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n",
    "            summarize_performance(i, g_model, c_model, latent_dim)\n",
    "\n",
    "    # line lots of loss\n",
    "    plot_history(c1_hist, c2_hist, g_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec modif du trainable\n",
    "\n",
    "# size of the latent space\n",
    "latent_dim = 50\n",
    "# create the critic\n",
    "critic = define_critic()\n",
    "opt = RMSprop(lr=0.00005)\n",
    "critic.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, critic)\n",
    "print(dataset.shape)\n",
    "# train model\n",
    "train(generator, critic, gan_model, dataset, latent_dim, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
