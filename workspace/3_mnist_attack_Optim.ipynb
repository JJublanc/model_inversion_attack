{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy - attack model - part1 : Wasserstein GAN\n",
    "\n",
    "reference for the WGAN : https://machinelearningmastery.com/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras import backend\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Add\n",
    "from keras import optimizers\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.sys.path.append(\"./src\")\n",
    "from utils import plot_img\n",
    "from utils import load_mnist_data\n",
    "from utils import pick_and_show_image\n",
    "\n",
    "from models import define_critic\n",
    "from models import generate_latent_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load private data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size : 30596\n",
      "test size : 5139\n",
      "total size : 35735\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_mnist_data(\"private\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 load the model attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = load_model(\"model/target_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 load the critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the id of the model. For example we choose the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file.split(\"_\")[-1].split(\".\")[0] for file in os.listdir(\"./model\")]\n",
    "model_num = [int(file) for file in files if not(file in ['checkpoints','loss','model'])]\n",
    "model_id = np.max(model_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the critic model is customed we build up a new model with the same architecture as the critic, load the weights of the one saved and load them into the new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_critic_model = define_critic()\n",
    "attack_critic_model.load_weights(\"model/attack_critic_model_weights_\" + str(model_id) + \".h5\")\n",
    "attack_critic_model.name = \"attack_critic_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 load the gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use two gan with different names so that the model do not have the same layers' name when combined in the optimization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "attack_gan_model_1 = load_model(\"model/attack_gan_model_\" + str(model_id) + \".h5\")\n",
    "attack_gan_model_1.name = \"attack_gan_model_1\"\n",
    "attack_gan_model_2 = load_model(\"model/attack_gan_model_\" + str(model_id) + \".h5\")\n",
    "attack_gan_model_2.name = \"attack_gan_model_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define optimization process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We design a model which intermediate layer is of the dimension of the latent space. We want to generate a point in the latent space (__x__) that makes the generator produce a credible image (hand written-digit-like) which will be classified by the target model as the target label.\n",
    "The outputs of the model are chosen to build a loss designed to perform this optimization program :\n",
    "- __attack_critic_model(attack_gan_model_1(x))__ which the critic of the image generated by the GAN, the more the image is credible, the higher will be this output ;\n",
    "- __target_model(attack_gan_model_2(x))__ which the class predicted by the target model, this one will be used to compute a difference with the label targetted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_model_optim(latent_dim=50, \n",
    "                           attack_critic_model=attack_critic_model, \n",
    "                           attack_gan_model_1=attack_gan_model_1, \n",
    "                           attack_gan_model_2=attack_gan_model_2):\n",
    "    \n",
    "    # generate a point in the latent space\n",
    "    main_input = Input(shape = (latent_dim,), name='main_input')\n",
    "    x = Dense(50,\n",
    "              activation='linear',\n",
    "              kernel_initializer = RandomNormal(mean=0.0, stddev=1, seed=None),\n",
    "              name = \"gen_attack_img\")(main_input)\n",
    "    gen_latent_values = Model(main_input, x)\n",
    "\n",
    "    # build up the model with the outputs that will be used to compute the loss\n",
    "    model = Model(inputs=main_input, outputs = [attack_critic_model(attack_gan_model_1(x)), target_model(attack_gan_model_2(x))])\n",
    "    \n",
    "    return model, gen_latent_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one layer should be trainable to perform the optimization process. If not we will retrain our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_not_optim_layers(model):\n",
    "    for layer in model.layers:\n",
    "        if layer.name == \"gen_attack_img\":\n",
    "            layer.trainable=True\n",
    "        else:\n",
    "            layer.trainable=False\n",
    "        # print(\"layer : {}, trainable {}\".format(layer.name, layer.trainable))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is compound of two parts :\n",
    "- the credibility : is the image reconstructed a credible hand written digit ?\n",
    "- the class proximity : is the class of the reconstructed image, the one targetted ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_optim_fn(target, lambda_):\n",
    "    def loss_optim(y_true, y_pred):\n",
    "        # credibility part : this part caracterize the credibility of the reconstructed image in the space of the public data\n",
    "        credibility = backend.mean(y_pred[0], axis=0)\n",
    "        \n",
    "        # proximity part : define the absolute difference between the predicted for the reconstructed image and the class targetted\n",
    "        proximity_to_target = backend.mean(y_pred[1], axis=0) - target\n",
    "        proximity_to_target = backend.abs(proximity_to_target)\n",
    "        proximity_to_target = backend.mean(proximity_to_target)/2\n",
    "        return backend.sum([credibility, lambda_*backend.log(proximity_to_target)], axis=-1)\n",
    "    return loss_optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Launch the whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim parameters\n",
    "lambda_= 100\n",
    "n_epochs = 150\n",
    "\n",
    "# inputs are constants and ouputs are not used\n",
    "x = np.full((640, 50), 1)\n",
    "model, _ = create_new_model_optim()\n",
    "y = model.predict(np.full((640, 50), 1)) # we do not use these values, there are just here to avoid errors when training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target probs : [0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "img, label = pick_and_show_image(x_train, y_train)\n",
    "target_probs = target_model.predict(np.reshape(img,(1,28,28,1)))\n",
    "print(\"target probs : {}\".format(target_probs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Make the optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization is repeated 5 times. The trial with best results is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_optim_fn(target_probs, lambda_)\n",
    "optimizer = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "batch_size = 64\n",
    "\n",
    "latent_reconstructed_list = []\n",
    "loss_list = []\n",
    "loss_1_list = []\n",
    "loss_2_list = []\n",
    "    \n",
    "for i in range(5) :\n",
    "    optim_model, gen_latent_values = create_new_model_optim()\n",
    "    optim_model = freeze_not_optim_layers(model)\n",
    "    optim_model.compile(optimizer=optimizer,loss=loss)\n",
    "    optim_model.fit(x, y, epochs=n_epochs, batch_size = batch_size)\n",
    "\n",
    "    latent_reconstructed = gen_latent_values.predict(np.full((1, 50), 1))\n",
    "    image_reconstructed = attack_gan_model_2.predict(latent_reconstructed)\n",
    "    credibility = attack_critic_model.predict(image_reconstructed)\n",
    "    gen_probs = target_model.predict(image_reconstructed)\n",
    "\n",
    "\n",
    "    latent_reconstructed_list.append(latent_reconstructed)\n",
    "\n",
    "    y_pred = optim_model.predict(x)\n",
    "    loss_result_1 = np.mean(y_pred[1], axis=0) - target_probs\n",
    "    loss_result_1 = np.abs(loss_result_1)\n",
    "    loss_result_1 = np.mean(loss_result_1)/2\n",
    "    loss_result_1 = lambda_*loss_result_1\n",
    "    loss_1_list.append(loss_result_1)\n",
    "        \n",
    "    loss_result_2 = np.mean(y_pred[0], axis=0)\n",
    "    loss_2_list.append(loss_result_2)\n",
    "        \n",
    "    loss_result = loss_result_1 + loss_result_2\n",
    "    loss_list.append(loss_result)\n",
    "        \n",
    "    del optim_model\n",
    "    del gen_latent_values\n",
    "\n",
    "    print(\"credibility : {}\".format(credibility))\n",
    "    print(\"classification : {}\".format(gen_probs))\n",
    "    print(\"\\n \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best one and save the experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.argmin(loss_list)\n",
    "\n",
    "\n",
    "results = {\"loss\" : loss_list[index],\n",
    "          \"latent_reconstructed\" : latent_reconstructed_list[index],\n",
    "          \"image_reconstructed\" : attack_gan_model_2.predict(latent_reconstructed_list[index])[0,:,:,0],\n",
    "          \"image_targetted\" : img,\n",
    "          \"label_targetted\" : label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title(\"image originale\")\n",
    "ax[1].imshow(results[\"image_reconstructed\"])\n",
    "ax[1].set_title(\"image reconstruite\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"results\" in os.listdir(\"./\"):\n",
    "    os.mkdir(\"results\")\n",
    "file_name = \"result_\" + str(len(os.listdir(\"./results\")))\n",
    "dir_name = \"./results\"\n",
    "file_path = os.path.join(dir_name, file_name)\n",
    "np.save(file_path, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
